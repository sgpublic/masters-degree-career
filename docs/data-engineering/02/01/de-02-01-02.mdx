# 2.1.2 评估指标介绍

对于分类问题，可将真实类别和预测类别分为以下四种情况。

<table>

<tr>
<th colSpan="2" rowSpan="2"></th>
<th colSpan="2">预测结果</th>
</tr>

<tr>
<th>正例（当前类别）</th>
<th>反例（其他类别）</th>
</tr>

<tr>
<th rowSpan="2">真实情况</th>
<th>正例（当前类别）</th>
<td>真正例 TP（True Positive）</td>
<td>假反例 FN（False Negative）</td>
</tr>

<tr>
<th>反例（其他类别）</th>
<td>假正例 FP（False Positive）</td>
<td>真反例 TN（True Negative）</td>
</tr>

</table>

即，预测正确为真，预测错误为假。

通常情况下，分类任务的模型输出结果是，样本属于当前类别的概率，是连续的数值，但我们会认为设定一个阈值，根据阈值将模型输出的概率解析为离散的分类。

## 2.1.2.1 F1-score

F1-score 是一种针对分类任务的性能指标，反应了模型对正例（当前类别）的预测准确度。

+ **查准率 P（Precision）**

  $$
  P=\frac{TP}{TP+FP}
  $$

  表示预测正例中预测正确的比例。

+ **查全率 R（Recall）**

  $$
  R=\frac{TP}{TP+FN}
  $$

  表示真实正例中预测正确的比例。

+ **F1-score**

  $$
  F1=\frac{2PR}{P+R}=\frac{2TP}{2TP+FN+FP}
  $$

## 2.1.2.2 AUC

+ **真正例率 TPR（True Positive Rate）**

  $$
  TPR=\frac{TP}{TP+FN}
  $$

  表示真实正例中预测正例的比例。

+ **假正例率 FPR（False Positive Rate）**

  $$
  FPR=\frac{FP}{TN+FP}
  $$

  表示真实反例中预测正例的比例。

+ **ROC 曲线（Receiver Operating Characteristic Curve）**

  由于分类任务通常需要设定一个阈值，那么不同的阈值将得到不同的真正例率 TPR 和假正例率 FPR，将这些值绘制到横坐标为假正例率、纵坐标为真正例率的坐标轴上，即可得到 ROC 曲线（通常情况下，随着阈值的变化，真正例率和假正例率的变化是平滑的，因此这些坐标能自然的练成一条曲线）

  当一个模型的 ROC 曲线完全在另一个模型的 ROC 曲线上方，则可断言前者的性能优于后者。

  ROC 曲线示意图：

  <SampleRocCurve />
+ **AUC（Area Under Curve）**

  即 ROC 曲线与横坐标轴围成的面积。通常认为 AUC 越大，模型的性能越好。

## 2.1.2.3 RMSE & MSE

**均方根误差 RMSE（Root Mean Squared Error）** 和**均方误差 MSE（Mean Squared Error）** 都是针对回归模型的。

均方误差 MSE：

$$
MSE=\frac{1}{m} \sum_{i=1}^{m}{(y_i-y'_i)^2}
$$

均方根误差 RMSE：

$$
RMSE=\sqrt{MSE}=\sqrt{\frac{1}{m} \sum_{i=1}^{m}{(y_i-y'_i)^2}}
$$

其中 $m$ 表示测试样例个数，$y_i$ 表示第 $i$ 个实例的真实目标值，$y'_i$ 表示第 $i$ 个实例的模型预测值。
